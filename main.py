import torch
import torch.nn as nn
import cv2
import numpy as np
from torchvision import models, transforms
from PIL import Image
from facenet_pytorch import MTCNN
import torch.nn.functional as F

# ===============================================================
# [1] í™˜ê²½ ì„¤ì • (ì´ ë¶€ë¶„ë§Œ ë³¸ì¸ ìƒí™©ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)
# ===============================================================

# í•™ìŠµí•  ë•Œ ì‚¬ìš©í•œ í´ë˜ìŠ¤ ì´ë¦„ (ì•ŒíŒŒë²³ ìˆœì„œëŒ€ë¡œ ì ì–´ì•¼ í•©ë‹ˆë‹¤!)
# ì˜ˆ: dataset í´ë” ì•ˆì— ['jisung', 'minji', 'unknown'] í´ë”ê°€ ìˆë‹¤ë©´ ê·¸ ìˆœì„œ ê·¸ëŒ€ë¡œ.
CLASS_NAMES = ['jisung', 'unknown'] 

# ë¬¸ì„ ì—´ì–´ì¤„ ì‚¬ëŒ ëª©ë¡
AUTHORIZED_USERS = ['jisung']

# ëª‡ % ì´ìƒ í™•ì‹ í•  ë•Œë§Œ ë¬¸ì„ ì—´ì–´ì¤„ì§€ (0.0 ~ 1.0)
# unknownì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ 0.8(80%) ì´ìƒ ì¶”ì²œ
CONFIDENCE_THRESHOLD = 0.85 

# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
MODEL_PATH = '/workspace/face_recog/model/face_model_20251202_060528.pth'

# ì˜ìƒ ì†ŒìŠ¤ (íŒŒì¼ ê²½ë¡œ ë˜ëŠ” 0)
VIDEO_SOURCE = '/workspace/face_recog/test/Image.jpg' 
# ===============================================================

# 1. ì¥ì¹˜ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸš€ ì‹¤í–‰ ì¥ì¹˜: {device}")

# 2. ë°ì´í„° ì „ì²˜ë¦¬ (í•™ìŠµí•  ë•Œì™€ ë˜‘ê°™ì´ ë§ì¶°ì•¼ í•¨)
# ResNetì€ 224x224 í¬ê¸°ë¥¼ ì¢‹ì•„í•©ë‹ˆë‹¤.
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# 3. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
print("ëª¨ë¸ ë¡œë”© ì¤‘...")
# (1) ë¼ˆëŒ€ ë§Œë“¤ê¸°
model = models.resnet18(weights=None) # ê»ë°ê¸°ë§Œ ê°€ì ¸ì˜´
num_ftrs = model.fc.in_features
# (2) ë§ˆì§€ë§‰ ì¸µ ê°œìˆ˜ ë§ì¶”ê¸° (í•™ìŠµí•œ í´ë˜ìŠ¤ ê°œìˆ˜ë§Œí¼)
model.fc = nn.Linear(num_ftrs, len(CLASS_NAMES)) 
# (3) ì €ì¥ëœ ê°€ì¤‘ì¹˜(Brain) ì‹¬ê¸°
try:
    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
except RuntimeError as e:
    print(f"âŒ ì—ëŸ¬ ë°œìƒ! í•™ìŠµëœ í´ë˜ìŠ¤ ê°œìˆ˜ì™€ CLASS_NAMES ê°œìˆ˜ê°€ ë‹¤ë¦…ë‹ˆë‹¤.\nì—ëŸ¬ ë‚´ìš©: {e}")
    exit()

model = model.to(device)
model.eval() # í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (Dropout ë“± ë¹„í™œì„±í™”)

# 4. ì–¼êµ´ ê°ì§€ê¸° (MTCNN) ë¡œë“œ
mtcnn = MTCNN(keep_all=True, device=device)

# 5. ì˜ìƒ ì²˜ë¦¬ ì‹œì‘
cap = cv2.VideoCapture(VIDEO_SOURCE)

# ì˜ìƒ ì €ì¥ ì„¤ì •
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = cap.get(cv2.CAP_PROP_FPS)
four