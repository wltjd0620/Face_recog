import cv2
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
from facenet_pytorch import MTCNN
import torch.nn.functional as F
import numpy as np
import time
from datetime import datetime
from collections import deque, Counter

# ===============================================================
# [1] ì‹œìŠ¤í…œ ì„¤ì • (Configuration)
# ===============================================================
VIDEO_SOURCE = 0  # ì›¹ìº  ë²ˆí˜¸
CLASS_NAMES = ['jisung', 'richard', 'unknown'] 
AUTHORIZED_USERS = ['jisung', 'richard'] # ìŠ¹ì¸ëœ ì‚¬ìš©ì ëª©ë¡

# [ì¤‘ìš”] ëª¨ë¸ ê²½ë¡œ (ë³¸ì¸ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • í•„ìˆ˜!)
MODEL_PATH = "./model/20251215_053604/face_model.pth"

# ---------------------------------------------------------------
# [2] ì•ˆì •í™” ì•Œê³ ë¦¬ì¦˜ ì„¤ì • (Hyperparameters)
# ---------------------------------------------------------------
# A. ë‹¤ìˆ˜ê²° ë²„í¼ (Flickering ë°©ì§€)
# ìµœê·¼ 10í”„ë ˆì„(ì•½ 0.3ì´ˆ)ì˜ ê²°ê³¼ë¥¼ ëª¨ì•„ì„œ ë‹¤ìˆ˜ê²°ë¡œ íŒë‹¨
BUFFER_SIZE = 10 

# B. ì´ì¤‘ ì„ê³„ê°’ (Hysteresis Locking)
# ì§„ì… ì¥ë²½: ì²˜ìŒ ì¸ì‹ë  ë•ŒëŠ” 85% ì´ìƒì´ì–´ì•¼ í•¨ (ì—„ê²©)
# ìœ ì§€ ì¥ë²½: í•œë²ˆ ë½(Lock)ì´ ê±¸ë¦¬ë©´ 50%ê¹Œì§€ ë–¨ì–´ì ¸ë„ ìœ ì§€ (ê´€ëŒ€)
HIGH_THRESHOLD = 0.85 
LOW_THRESHOLD = 0.50

# C. ì˜¤ì¸ì‹ ë°©ì§€ (Safety Breakers)
# í…”ë ˆí¬íŠ¸ ë°©ì§€: ì–¼êµ´ì´ 0.1ì´ˆ ë§Œì— 100í”½ì…€ ì´ìƒ ì›€ì§ì´ë©´ ì´ˆê¸°í™”
MAX_MOVE_DISTANCE = 100 
# ===============================================================

def run_dashboard():
    # 1. ì¥ì¹˜ ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ ì‹œìŠ¤í…œ ì‹œì‘... (Device: {device})")
    
    # 2. ì „ì²˜ë¦¬ ì •ì˜ (ResNet ì…ë ¥ ê·œê²©)
    preprocess = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # 3. ëª¨ë¸ ë¡œë“œ
    print("ğŸ› ï¸ ëª¨ë¸ ë¡œë”© ì¤‘...")
    try:
        model = models.resnet18(weights=None)
        model.fc = nn.Linear(model.fc.in_features, len(CLASS_NAMES))
        model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
        model.to(device)
        model.eval()
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    except Exception as e:
        print(f"ğŸš¨ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print(f"ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {MODEL_PATH}")
        return

    # 4. MTCNN (ì–¼êµ´ ê°ì§€ê¸°)
    mtcnn = MTCNN(keep_all=True, device=device)
    
    cap = cv2.VideoCapture(VIDEO_SOURCE)
    
    # -----------------------------------------------------------
    # [ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”]
    # -----------------------------------------------------------
    # UI ë ˆì´ì•„ì›ƒ
    layout_width, layout_height = 1000, 480
    
    # ë¡œê·¸ ê´€ë ¨
    access_logs = deque(maxlen=5)
    last_log_time = time.time()
    
    # ì•Œê³ ë¦¬ì¦˜ ê´€ë ¨
    prediction_buffer = deque(maxlen=BUFFER_SIZE) # ìµœê·¼ ê²°ê³¼ ì €ì¥ì†Œ
    current_locked_user = None # í˜„ì¬ ë½ì˜¨ëœ ì‚¬ìš©ì
    prev_center = None # ì´ì „ í”„ë ˆì„ ì–¼êµ´ ì¤‘ì‹¬ì  (ì´ë™ ê°ì§€ìš©)

    print("ğŸ¥ ëŒ€ì‹œë³´ë“œ ì‹¤í–‰ (ì¢…ë£Œí•˜ë ¤ë©´ 'q'ë¥¼ ëˆ„ë¥´ì„¸ìš”)")

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break

        # í”„ë ˆì„ ë¦¬ì‚¬ì´ì¦ˆ (ì²˜ë¦¬ ì†ë„ ë° UI ê·œê²© í†µì¼)
        frame = cv2.resize(frame, (640, 480))
        
        # -------------------------------------------------------
        # [UI] ë°°ê²½ ê·¸ë¦¬ê¸°
        # -------------------------------------------------------
        dashboard = np.zeros((layout_height, layout_width, 3), dtype=np.uint8)
        dashboard[0:480, 0:640] = frame # ì™¼ìª½: ì¹´ë©”ë¼
        
        # ì˜¤ë¥¸ìª½ ì •ë³´ì°½ ë°°ê²½ (Dark Grey)
        ui_x_start = 640
        cv2.rectangle(dashboard, (ui_x_start, 0), (layout_width, layout_height), (30, 30, 30), -1)

        # -------------------------------------------------------
        # [AI] ì–¼êµ´ ì¸ì‹ ë° ë¡œì§ ì²˜ë¦¬
        # -------------------------------------------------------
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(frame_rgb)
        
        # ì–¼êµ´ ê°ì§€
        boxes, _ = mtcnn.detect(pil_img)

        # ê¸°ë³¸ê°’ (ì•„ë¬´ë„ ì—†ì„ ë•Œ)
        final_decision_name = "Scanning..."
        final_prob = 0.0
        current_status = "STANDBY"
        status_color = (100, 100, 100)
        target_text_ui = "SCANNING..."

        if boxes is not None:
            # ê°€ì¥ í° ì–¼êµ´ í•˜ë‚˜ë§Œ ì²˜ë¦¬ (Focusing)
            box = boxes[0] 
            x1, y1, x2, y2 = [int(b) for b in box]
            
            # [ì•ˆì „ì¥ì¹˜ 1] í…”ë ˆí¬íŠ¸ ê°ì§€ (ìœ„ì¹˜ ê¸‰ë³€ í™•ì¸)
            current_center = ((x1 + x2) // 2, (y1 + y2) // 2)
            if prev_center is not None:
                dist = np.sqrt((current_center[0] - prev_center[0])**2 + (current_center[1] - prev_center[1])**2)
                if dist > MAX_MOVE_DISTANCE: 
                    # ì‚¬ëŒì´ íœ™ ë°”ë€Œì—ˆë‹¤ê³  íŒë‹¨ -> ì´ˆê¸°í™”
                    prediction_buffer.clear()
                    current_locked_user = None
            prev_center = current_center

            # ì–¼êµ´ ì´ë¯¸ì§€ ì˜ë¼ë‚´ê¸° (Crop)
            face_img = pil_img.crop((max(0,x1), max(0,y1), min(640,x2), min(480,y2)))
            
            try:
                # ResNet ì¶”ë¡ 
                input_tensor = preprocess(face_img).unsqueeze(0).to(device)
                with torch.no_grad():
                    outputs = model(input_tensor)
                    probs = F.softmax(outputs, dim=1)
                    max_prob, idx = torch.max(probs, 1)
                    
                    raw_prob = max_prob.item()
                    raw_name = CLASS_NAMES[idx.item()]

                # ---------------------------------------------------
                # [í•µì‹¬ ë¡œì§] ë½í‚¹ & íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ & ID ê²€ì¦
                # ---------------------------------------------------
                
                # [ì•ˆì „ì¥ì¹˜ 2] ID ë³€ê²½ ê°ì§€ (ë½ ìƒíƒœì¸ë°, ë‹¤ë¥¸ ì‚¬ëŒ í™•ë¥ ì´ ë†’ìŒ)
                if current_locked_user is not None:
                    if raw_name != current_locked_user and raw_prob > 0.6:
                        current_locked_user = None
                        prediction_buffer.clear()
                
                # ì„ê³„ê°’ ê²°ì • (ë½ ìƒíƒœë©´ ê´€ëŒ€í•˜ê²Œ, ì•„ë‹ˆë©´ ì—„ê²©í•˜ê²Œ)
                threshold = LOW_THRESHOLD if current_locked_user else HIGH_THRESHOLD
                
                # 1ì°¨ íŒë‹¨
                detected_name = raw_name if raw_prob >= threshold else "unknown"

                # ë²„í¼ ì €ì¥ ë° ë‹¤ìˆ˜ê²° íˆ¬í‘œ
                prediction_buffer.append(detected_name)
                
                if len(prediction_buffer) > 0:
                    most_common_name, count = Counter(prediction_buffer).most_common(1)[0]
                    # ê³¼ë°˜ìˆ˜ ì´ìƒ ë™ì˜ ì‹œ ì±„íƒ
                    if count >= (len(prediction_buffer) // 2):
                        final_decision_name = most_common_name
                    else:
                        final_decision_name = "unknown"
                else:
                    final_decision_name = "unknown"

                # ë½ ìƒíƒœ ê°±ì‹ 
                if final_decision_name in AUTHORIZED_USERS:
                    current_locked_user = final_decision_name
                elif final_decision_name == "unknown":
                    current_locked_user = None # Unknownì´ë©´ ë½ í•´ì œ

                # ì‹œê°í™”ìš© ë³€ìˆ˜ í• ë‹¹
                final_prob = raw_prob
                
                # ì–¼êµ´ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                box_color = (0, 255, 0) if final_decision_name in AUTHORIZED_USERS else (0, 0, 255)
                cv2.rectangle(dashboard, (x1, y1), (x2, y2), box_color, 2)

            except Exception:
                pass
        else:
            # ì–¼êµ´ ì—†ìœ¼ë©´ ëª¨ë“  ìƒíƒœ ì´ˆê¸°í™”
            prediction_buffer.clear()
            current_locked_user = None
            prev_center = None

        # -------------------------------------------------------
        # [ìƒíƒœ ê²°ì •]
        # -------------------------------------------------------
        if final_decision_name in AUTHORIZED_USERS:
            current_status = "ACCESS GRANTED"
            status_color = (0, 255, 0) # Green
            target_text_ui = final_decision_name.upper()
        elif final_decision_name == "unknown":
            current_status = "ACCESS DENIED"
            status_color = (0, 0, 255) # Red
            target_text_ui = "UNKNOWN"
        else:
            # Scanning...
            pass

        # -------------------------------------------------------
        # [ë¡œê·¸ ê¸°ë¡] (1ì´ˆ Throttling)
        # -------------------------------------------------------
        if current_status != "STANDBY":
            curr_time = time.time()
            if curr_time - last_log_time >= 1.0:
                timestamp = datetime.now().strftime("%H:%M:%S")
                log_text = f"[{timestamp}] {target_text_ui}"
                
                # ì¤‘ë³µ ë¡œê·¸ ë°©ì§€ (ì„ íƒì‚¬í•­)
                if not access_logs or access_logs[-1] != log_text:
                    access_logs.append(log_text)
                    last_log_time = curr_time

        # -------------------------------------------------------
        # [UI ê·¸ë¦¬ê¸°] ì˜¤ë¥¸ìª½ ì •ë³´ íŒ¨ë„
        # -------------------------------------------------------
        # 1. í—¤ë”
        cv2.putText(dashboard, "AI SECURITY SYSTEM", (ui_x_start + 20, 40), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)
        cv2.line(dashboard, (ui_x_start + 20, 50), (layout_width - 20, 50), (100, 100, 100), 1)

        # 2. ìƒíƒœ ë°°ë„ˆ (í¬ê²Œ)
        cv2.rectangle(dashboard, (ui_x_start + 20, 70), (layout_width - 20, 130), status_color, -1)
        cv2.putText(dashboard, current_status, (ui_x_start + 35, 110), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 3)

        # 3. ì¸ì‹ëœ ì‚¬ìš©ì ì´ë¦„
        cv2.putText(dashboard, "DETECTED USER:", (ui_x_start + 20, 170), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
        cv2.putText(dashboard, target_text_ui, (ui_x_start + 20, 200), 
                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)

        # 4. ì‹ ë¢°ë„ ê²Œì´ì§€ (Bar Chart)
        cv2.putText(dashboard, f"CONFIDENCE: {final_prob*100:.1f}%", (ui_x_start + 20, 240), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
        # ê²Œì´ì§€ ë°°ê²½
        cv2.rectangle(dashboard, (ui_x_start + 20, 250), (layout_width - 20, 270), (50, 50, 50), -1)
        # ê²Œì´ì§€ ê°’
        bar_width = int((layout_width - 20 - (ui_x_start + 20)) * final_prob)
        cv2.rectangle(dashboard, (ui_x_start + 20, 250), (ui_x_start + 20 + bar_width, 270), status_color, -1)

        # 5. ì ‘ì† ë¡œê·¸ (ìƒ‰ìƒ ìë™ ì ìš©)
        cv2.putText(dashboard, "ACCESS LOG:", (ui_x_start + 20, 310), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
        
        y_log = 335
        for log in access_logs:
            # AUTHORIZED_USERSì— í¬í•¨ëœ ì´ë¦„ì´ ë¡œê·¸ì— ìˆìœ¼ë©´ ì´ˆë¡ìƒ‰, ì•„ë‹ˆë©´ ë¹¨ê°„ìƒ‰
            if any(user.upper() in log for user in AUTHORIZED_USERS):
                log_color = (0, 255, 0)
            else:
                log_color = (0, 0, 255)

            cv2.putText(dashboard, log, (ui_x_start + 20, y_log), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, log_color, 1)
            y_log += 25

        # 6. í•˜ë‹¨ ì‹œìŠ¤í…œ ì •ë³´
        cv2.line(dashboard, (ui_x_start + 20, 440), (layout_width - 20, 440), (100, 100, 100), 1)
        cv2.putText(dashboard, "Model: ResNet18 | GPU: ON", (ui_x_start + 20, 465), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (100, 100, 100), 1)

        # í™”ë©´ ì¶œë ¥
        cv2.imshow('AI Face Dashboard', dashboard)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    run_dashboard()